While computer power has increased exponentially over the past several years, we still rely on the same interface that was created over 20 years ago, namely a 2D screen with interactions using a keyboard and mouse.
While this is sufficient for everyday tasks, it is quickly becoming more and more cumbersome on designers of 3D objects (architects, mechanical engineers, 3D artists, etc)\cite{Dekker199242}.

There are few models/prototypes exsiting which have served as inspiration and provided a starting point when developing the prototype. A few have been mentioned here.

When dealing with 3D objects, it is always easier to design and visualize the end product when working with model builders which enable 3D construction rather 2D construction. One of the first 3D tools developed was the 3D construct\cite{Kaufmann:Usability}. Tool aimed to give a better sense of the 3D objects creation and properties to high school students\cite{Kaufmann:LearningGeometry}. The tool used a menu projected onto a tablet. This menu was then segregated into different tabs with logically grouped functions under each tab. We use the same concept of logically grouping the functions under each tab but have eliminated the cumbersome tablet. The menu has been developed to pop up in front of the user and can be turned off when needed. 

Other research has given evidence that careful attention needs to be placed on the method of interaction\cite{Bowman98interactiontechniques}. The interactions which is need in a virtual environment and the levels of interaction functions which needs to be implemented has been outlined in the 'Design and Evaluation of Domain-Specific Interaction Techniques in the AEC Domain for Immersive Virtual Environments'\cite{AEC}, 'Interactive 3D Geometrical Modelers for Virtual Reality and Design'\cite{Interactive} and 'Understanding Virtual Reality Technology: Advances and Applications' \cite{AdvanceAndApplication} papers. 

The world builder prototype aimed to build a virtual world using different objects. There was no need for precision or specialized knowledge of the object shapes (precise 3D models) and also eliminated the need for high-level editing and revision. The SKETCH\cite{SKETCH} interface gave us the idea of building a system aimed at achieving ease of low-level correction and revision. This helped us eliminate some of the non-intuitive manipulation techniques to be developed. The manipulation of object is restricted to scaling an object or rotating an object in the current developed prototype. This paper also discusses the fact that we need to focus on the placement of the object rather than changing the structure of the object.

The decision to use two Wii remote rather than tracking the users hand was made by observing the difficulties demonstrated in SKETCH\cite{SKETCH} and Surface Drawing \cite{Drawing} systems. By using the buttons on the Wii to manipulate the virtual world, we eliminated the need to recognize the patterns made by the userâ€™s hand. As shown in the systems discussed here, it is rather difficult for a user to learn a particular gesture to manipulate the environment compared to pressing a button or selecting the type of manipulation to be performed from a menu. Since the tracking of the hand is eliminated, the system performance is also improved.

Bimanual interaction has been shown to allow the user more fine-grained and contextual control\cite{Zeleznik:1997:TPI:253284.253316}.
Some research has shown that using an augmented reality system to construct a virtual world alongside a real one provides intuitive benefit\cite{Jota:2011:CVM:1979742.1979915}.

We plan on breaking the design in to several pieces such as creation, editing, and grouping. This allows the user to focus on the task at hand, creating a more efficient workflow\cite{Butterworth:1992:3DM}.

Since we are using 6DOF devices based on where the users' hands are, we can take advantage of proprioception.
This allows the user to have a more physical ``sense'' of where the object is being moved \cite{Mine:MovingObjects}.
We allow the user to point and select in a 3D space, which gives the user more fine-grained control of individual points on the object \cite{5759472}.
This could be extended to allow a user to manipulate individual points (vertices) on an object, giving very precise control of the detail of the object.
Dexterity in IVEs is also a problem, one group used a pressure sensitive notepad tracked in 3D to simulate a digitizer which allowed manipulation of objects in the environment\cite{658467}.
We will be overcoming this problem by using two 6DOF devices for interaction, this way, the user will have very fine control over each object.

Selection techniques often use ray casting.
Some work focused on pointing from the user's hand\cite{Mine:MovingObjects}.
Others used the user's eye as the start of the ray\cite{Pierce:1997:IPI:253284.253303}.
More recent research has indicated that a combination of the two leads to the best results for user accuracy\cite{5307641}.
We will be focusing on a novel technique which we call Virtual Hand Casting.

There have been extensive studies on locomotion within IVEs, such as World in Miniature\cite{Pausch:WorldInMiniature}.
We will be using a modified World in Miniature scheme. The user will be able to shrink the world around them, thereby allowing them to navigate quickly and efficiently, without taking up valuable space in the display. When dealing with scaling of the virtual environment, we need to decide on hierarchical levels of scale available in the same environment (scaling the world or scaling the object) and also how to inform the user about the state of the world (It has been scaled or not). \cite{MSVE}

One feature that is very promising is the automatic creation of object based on shape grammars\cite{Goswell:ShapeGrammer}.
This allows a user to define a ``rule'' for creating an object, and the system can create multiple variances of that object for them.

There is evidence portraying the lack of useful computer based tools for architecture, especially within architecture education\cite{Dobson:Architecture}.
Our system will allow the design and study of full-scale buildings in minute detail.
Once real-world simulation effects are in place, the user could add a life-size skyscraper and view the effects of gravity and wind at the top floors.

The ability of an IVE to design and view 3D models dynamically extends well beyond architecture and simple CAD.
Volkswagen has been designing a virtual reality system, RAMSIS, that allows its engineers to study the styling and design of their vehicles before production\cite{Purschke:Cars}.
We believe we can take this one step further: by allowing a user to bring a model in to the world, the user can design an entire world and place objects, such as cars, within it.

Another exciting possibility for the uses of a generic 3D design system is that of Micro-Electro-Mechanical Systems (MEMS)\cite{Zhao:MEMS}.
By extending our system to allow for real-world simulation effects, the user could prototype the device and studies its behavior in an intuitive manner.

To improve the real-worlds simulation effects, we need to add to haptic feedback\cite{Interactions} and auditory cues\cite{VAS} to the system. Few systems have already been developed to should the effect of using haptic feedback\cite{Vishap} and 3D sound\cite{ASR}. 


